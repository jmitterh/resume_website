-	Analyzed large energy datasets to identify trends and anomalies that informed strategic decisions and product enhancements; partnered with business stakeholders to clarify data needs and translate them into technical deliveries.
-	Developed and maintained interactive dashboards and reports in Power BI, Tableau, and Imply Pivot (Druid), delivering clear, actionable insights to internal teams and clients.
-	Leveraged Python (Pandas, Polars, Plotly, Matplotlib) to build reusable data transforms, validations, and utilities that improved data quality and accelerated analytics and reporting.
-	Designed and executed complex SQL and configured Athena tables/partitions to enhance data accessibility, performance, and downstream modeling.
-	Initiated and led POCs to refine forecast models and create new data products using Athena SQL; documented outcomes and folded successful patterns into standard workflows.
-	Automated and optimized data workflows with Apache Airflow (DAG design, dependencies, alerting), improving freshness, reliability, and delivery SLAs for critical datasets.
-	Performed rigorous data diagnostics and exception handling across raw and processed layers, increasing trust in metrics and reducing time-to-detect for upstream issues.
-	Produced detailed, data-driven client reports supporting forecast management and risk assessment; presented findings and recommendations to stakeholders on a regular cadence.
-	Maintained high standards of data integrity through validation frameworks, schema checks, and comprehensive documentation of assumptions, lineage, and runbooks.
-	Collaborated cross-functionally with Product and Operations to align data solutions with user needs; contributed to design discussions and sprint planning to deliver on time.
-	Authored and maintained technical documentation and SOPs in Confluence to enable repeatability and smooth hand-offs across teams.
-	Reported progress bi-weekly using Agile practices in Jira; captured risks, blockers, and mitigation plans to keep initiatives on track.
-	Managed AWS services (S3, Athena) and Apache Druid alongside BI tooling, standardizing patterns for ingestion from files/APIs into centralized analytics layers.
-	Key Skills: Python (Pandas, Polars, Plotly, Matplotlib), SQL (Athena/Presto; Postgres exposure), ETL/ELT & Airflow, REST/API & file-based ingestion, Data Diagnostics & Validation, AWS (S3, Athena), Apache Druid/Imply Pivot, Power BI, Tableau, Agile (Jira), Documentation (Confluence)


##### Project Experience
Individual Project: Integration of Live Demo Dataset into Current Platform, Innowatts___________November 2022

*Introduction to Demo Dataset Anonymization at Innowatts*

At Innowatts, I spearheaded the first development of a customer data anonymization process for creating demo datasets. This initiative was aimed at establishing a live demo environment reflecting current market trends and data patterns. The project involved designing a system that not only maintained up-to-date data but also ensured compliance with privacy standards. My role was instrumental in transforming this vision into a functional reality, making the live demo environment a valuable asset for client demonstrations and market analyses.

*Technical Execution and Innovations*

The anonymization process I developed involved complex data handling, beginning with extraction from designated AWS S3 bucket locations, followed by meticulous anonymization and formatting procedures. I employed advanced scripting in this multi-faceted task, ensuring the integrity of data while transforming it into a standardized, anonymized format suitable for analysis and demonstrations. The end-to-end process included deploying scripts on Innowatts’ in-house infrastructure, managing large-scale data processing, and ensuring data security and compliance. This system was optimized to handle the computational demands efficiently, demonstrating significant improvements in both data processing and operational costs.

*Operational Impact and Data Management*

Under my guidance, the anonymization process was integrated into a regular operational schedule, ensuring the constant availability of up-to-date and relevant anonymized data. I established a methodical workflow, including data extraction, processing, and secure re-uploading to AWS S3 in a distinct location for anonymized datasets. This streamlined process greatly enhanced our ability to access and utilize anonymized data across various Athena environments, serving different operational needs from production-level analysis to development and testing. My contributions significantly elevated Innowatts’ capabilities in handling and utilizing large datasets for diverse client and market segments.
